{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivor Dataset\n",
    "\n",
    "This is my first ML project from Kaggle. The dataset have various information about pepole who survived or died from the tragedy. Using this data, I will build a model based on which I can predict the probability of other people's survival using their features like sex, age, fare, etc. This is a classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "# ignore Deprecation Warning\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning,RuntimeWarning) \n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load and Check Data\n",
    "Load data and pre-process to feed into ML. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12) (418, 11) \n",
      " ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked'] \n",
      " ['PassengerId' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch' 'Ticket' 'Fare'\n",
      " 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Some quick inspections\n",
    "print(train_df.shape, test_df.shape, '\\n', train_df.columns.values, '\\n', test_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only \"Age\", \"Cabin\", \"Embarked\", \"Fare\" have null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Outlier Detection\n",
    "- Outliers distort the picture of the data we obtain using descriptive statitics and data visualization. When our goal is to understand the data, it is often worthwhile to disregard outliers.\n",
    "- Outliers play havoc with many machine learning algorithms and statistical models. When our goal is to predict, our models are often improved by ignoring outliers.\n",
    "- Outliers can be exactly what we want to learn about, especially for tasks like anomaly detection.\n",
    "- Note that the variable must be continuous, not categorical, for any of these functions to make sense.\n",
    "\n",
    "Here we use the Modified Z-score method & the IQR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outliers_modified_z_score(dataframe, n, features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the modified z-score Method\n",
    "    \"\"\"\n",
    "    threshold = 3.5\n",
    "    outlier_indices = []\n",
    "    for col in features:\n",
    "        median_y = np.median(dataframe[col])\n",
    "        median_absolute_deviation_y = np.median([np.abs(y - median_y) for y in dataframe[col]])\n",
    "        modified_z_scores = [0.6745 * (y - median_y) / median_absolute_deviation_y for y in dataframe[col]]\n",
    "        outlier_list_col = dataframe[np.abs(modified_z_scores) > threshold].index\n",
    "       # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    return multiple_outliers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop_1 = outliers_modified_z_score(train_df,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>23.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>37.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>52.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>18.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>262.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>40.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>134.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>24.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>36.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>64.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>263.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>39.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>39.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110.8833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>60.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>24.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>49.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110.8833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>21.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>262.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>70.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>48.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>36.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>11.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>52.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>39.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>45.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>164.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>47.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  SibSp  Parch      Fare\n",
       "27   19.00      3      2  263.0000\n",
       "88   23.00      3      2  263.0000\n",
       "159    NaN      8      2   69.5500\n",
       "180    NaN      8      2   69.5500\n",
       "201    NaN      8      2   69.5500\n",
       "248  37.00      1      1   52.5542\n",
       "262  52.00      1      1   79.6500\n",
       "297   2.00      1      2  151.5500\n",
       "305   0.92      1      2  151.5500\n",
       "311  18.00      2      2  262.3750\n",
       "319  40.00      1      1  134.5000\n",
       "324    NaN      8      2   69.5500\n",
       "341  24.00      3      2  263.0000\n",
       "390  36.00      1      2  120.0000\n",
       "435  14.00      1      2  120.0000\n",
       "438  64.00      1      4  263.0000\n",
       "498  25.00      1      2  151.5500\n",
       "558  39.00      1      1   79.6500\n",
       "581  39.00      1      1  110.8833\n",
       "587  60.00      1      1   79.2000\n",
       "615  24.00      1      2   65.0000\n",
       "698  49.00      1      1  110.8833\n",
       "742  21.00      2      2  262.3750\n",
       "745  70.00      1      1   71.0000\n",
       "754  48.00      1      2   65.0000\n",
       "763  36.00      1      2  120.0000\n",
       "792    NaN      8      2   69.5500\n",
       "802  11.00      1      2  120.0000\n",
       "820  52.00      1      1   93.5000\n",
       "835  39.00      1      1   83.1583\n",
       "846    NaN      8      2   69.5500\n",
       "856  45.00      1      1  164.8667\n",
       "863    NaN      8      2   69.5500\n",
       "871  47.00      1      1   52.5542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]].loc[Outliers_to_drop_1] # Show the outliers rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outliers_iqr(dataframe, n, features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "    for col in features:\n",
    "        # 1st quartile (25%) & # 3rd quartile (75%)\n",
    "        quartile_1, quartile_3 = np.percentile(dataframe[col], [25,75])\n",
    "        #quartile_3 = np.percentile(dataframe[col], 75)\n",
    "      \n",
    "        iqr = quartile_3 - quartile_1\n",
    "        lower_bound = quartile_1 - (iqr * 1.5)\n",
    "        upper_bound = quartile_3 + (iqr * 1.5)\n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = dataframe[(dataframe[col] < lower_bound) | (dataframe[col] > upper_bound)].index\n",
    "       # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    return multiple_outliers   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "Outliers_to_drop = outliers_iqr(train_df,2, [\"Age\",\"SibSp\",\"Parch\",\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>23.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch    Fare\n",
       "27   19.0      3      2  263.00\n",
       "88   23.0      3      2  263.00\n",
       "159   NaN      8      2   69.55\n",
       "180   NaN      8      2   69.55\n",
       "201   NaN      8      2   69.55\n",
       "324   NaN      8      2   69.55\n",
       "341  24.0      3      2  263.00\n",
       "792   NaN      8      2   69.55\n",
       "846   NaN      8      2   69.55\n",
       "863   NaN      8      2   69.55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]].loc[Outliers_to_drop] # Show the outliers rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We detect 10 outliers. The 28, 89 and 342 passenger have an high \n",
    "Ticket Fare\n",
    "\n",
    "The 7 others have very high values of SibSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e9066d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAE3CAYAAACuIJvEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM/BIkqTk/X932MCbGcbpdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11499b4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((axis1, axis2), (axis3, axis4)) = plt.subplots(2,2, sharex=False, figsize=(10,5))\n",
    "sns.boxplot('Age', data=train_df, ax=axis1)\n",
    "sns.boxplot('Fare',data=train_df, ax=axis2)\n",
    "sns.boxplot('SibSp', data=train_df, ax=axis3)\n",
    "sns.boxplot('Parch',data=train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "train_df = train_df.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Join training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Join train and test datasets in order to obtain the same number of features during categorical conversion\n",
    "df = train_df.append(test_df, ignore_index=True)\n",
    "\n",
    "#train_len = len(train)\n",
    "#dataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Check for null and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill empty and NaNs values with NaN\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age and Cabin features have significant amount of missing values.\n",
    "\n",
    "Survived missing values correspond to the testing dataset (Survived column doesn't exist in test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Analysis\n",
    "Missing values will be filled. Catagorital feastures will be transformed to numberical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Numerical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Correlation between numberical values\n",
    "Look at the Correlation matrix between numerical values (SibSp, Parch, Age and Fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = sns.heatmap(train_df[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Fare seems to have a significant correlation with the survival probility (0.26). \n",
    "These pairs seem to be correlated too: \n",
    "- SibSp vs Parch (0.41)\n",
    "- Fare vs Parch (0.22)\n",
    "- SibSp vs Age (-0.31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will look at each feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parch & SibSp\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore SibSp feature vs Survived\n",
    "#fig, (axis1, axis2) = plt.subplots(1,2, sharex=False, figsize=(10,3))\n",
    "sns.factorplot(x=\"SibSp\",y=\"Survived\",data=df)\n",
    "#axis1.set_ylabels(\"survival probability\")\n",
    "sns.factorplot(x=\"Parch\",y=\"Survived\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Passengers with more families have lower probability to survive.\n",
    "- \n",
    "- There is a clear devision in the survival of passengers with 3 parents/children\n",
    "Instead of having 2 columns, Parch and SibSp, we can have only one column representing if the passenger had any families aboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Family'] = df['Parch'] + df['SibSp']+1\n",
    "# inspect the correlation between Family and Survived\n",
    "df[['Family', 'Survived']].groupby(['Family'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.factorplot(x=\"Family\",y=\"Survived\",data=df)\n",
    "g.set_ylabels('Survival Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of family members\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Family', data=df, ax=axis1)\n",
    "\n",
    "# average of survived for those who had/didn't have any families\n",
    "family_perc = df[['Family','Survived']].groupby(['Family'], as_index=False).mean()\n",
    "sns.barplot(x='Family',y='Survived',data=family_perc, ax=axis2)\n",
    "#axis1.set_xticklabels(['With Family','Alone'],rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the family size\n",
    "df['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The survivial rate increases with the family size till Family>=5. However, the number of family with >=5 members is only 57. Besides, peole with big families (>=5) have a low survival rate too. Thereby, I will combine the data with Family>4 into one category, Family=5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Family = df.Family.map(lambda x: 5 if x>4 else x)\n",
    "df[['Family','Survived']].groupby(['Family'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of family members\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Family', data=df, ax=axis1)\n",
    "\n",
    "# average of survived for those who had/didn't have any families\n",
    "family_perc = df[['Family','Survived']].groupby(['Family'], as_index=False).mean()\n",
    "sns.barplot(x='Family',y='Survived',data=family_perc, ax=axis2)\n",
    "#axis1.set_xticklabels(['With Family','Alone'],rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to indicator values \n",
    "df = pd.get_dummies(df, columns=['Family'], prefix='Fsize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop \"Parch\" & \"SibSp\"\n",
    "#df = df.drop(['Parch','SibSp'], axis=1)\n",
    "#df = df.drop(['Parch','SibSp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 263 missing values in Age. This can probably be inferred from other feasures, e.g., Title, Fare, SibSp, Parch, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(df, hue = 'Survived', aspect=4)\n",
    "#facet.map(sns.distplot, 'Age')\n",
    "facet.map(sns.kdeplot, 'Age', shade=True)\n",
    "facet.set(xlim=(0, df['Age'].max()))\n",
    "facet.add_legend()\n",
    "\n",
    "\n",
    "# Averge survived passeangers by age\n",
    "fig, axis1 = plt.subplots(1, 1, figsize=(18,4))\n",
    "average_age = df[['Age','Survived']].groupby(['Age'], as_index=False).mean()\n",
    "sns.barplot(x='Age', y='Survived', data=average_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age distribution seems to be a skewed gaussian distribution. \n",
    "- The distributions for survived and not survived people are different. The peak age for survived people is ~ 30, while the one for not survived people is ~ 25. \n",
    "- There are more people with age < 10 (children) survived, while fewer people with age > 60 survived. \n",
    "- As this feature is correlated with the survival rate, I will fill in the missing values. I will look at the most correalted features with Age (SibSp, Pclass, Parch and Sex). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NAN\n",
    "df.Fare.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one missing Fare value. I will fill it with the median value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Ticket[df.Fare.isnull()],'\\n', df.Pclass[df.Fare.isnull()], '\\n', df.Embarked[df.Fare.isnull()], '\\n', df.Cabin[df.Fare.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no corresponding value for Cabin, so only look at the relation between Fare and the other three feasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Fare'] = df['Fare'].fillna(df['Fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(df, hue = 'Survived', aspect=4)\n",
    "#facet.map(sns.distplot, 'Age')\n",
    "facet.map(sns.kdeplot, 'Fare', shade=True)\n",
    "facet.set(xlim=(0, df['Fare'].max()))\n",
    "facet.add_legend()\n",
    "facet.set_ylabels('Sruvival Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Fare\"].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the Fare distributions are very right-skewed for both Survived and not Survived. The skewness may cause overweight of the high-end values in the model. Thereby, i will log transform it to reduce the skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fare'] = df['Fare'].map(lambda x: np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(df, hue = 'Survived', aspect=4)\n",
    "facet.map(sns.distplot, 'Fare')\n",
    "facet.set(xlim=(0, df['Fare'].max()))\n",
    "facet.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Fare\"].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bin Fare into five intervals with equal amount of people\n",
    "# df['Fare_bin'] = pd.qcut(df.Fare,5,labels=[1,2,3,4,5]).astype(int)\n",
    "\n",
    "# inspect the correlation between Fare-bin and Survived\n",
    "#df[['Fare_bin', 'Survived']].groupby(['Fare_bin'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[['Fare_bin','Survived']].groupby(['Fare_bin'],as_index=False).mean().plot.scatter('Fare_bin','Survived')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the correlation between Fare and Survived is clear after the binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.2 Categorical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NAN\n",
    "df.Cabin.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is highly imcomplete. There are two choices: (1)map the missing ones to a new category \"unknown\" (2) drop this feasure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin[df.Cabin.notnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first letter of the cabin probably indicates the Desk, Thereby I  chose to keep this information only, since it indicates the probable location of the passenger in the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace the Cabin number by the type of cabin 'X' if not\n",
    "df.Cabin = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in df.Cabin ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(df[\"Cabin\"], ax=axis1, order=['A','B','C','D','E','F','G','T','X'])\n",
    "sns.factorplot(y=\"Survived\",x=\"Cabin\", data=df,kind=\"bar\", ax=axis2, order=['A','B','C','D','E','F','G','T','X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the low number of passenger that have a cabin, survival probabilities have an important standard deviation and we can't distinguish between survival probability of passengers in the different desks.\n",
    "\n",
    "But we can see that passengers with a cabin have generally more chance to survive than passengers without (X).\n",
    "\n",
    "It is particularly true for cabin B, C, D, E and F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = [\"Cabin\"],prefix=\"Cabin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NAN\n",
    "df.Embarked.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna({'Embarked':'S'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"S\" is the most occurred value. Thereby we will fill nulll values with \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the correlation between Embarked and Survived as well as some other features\n",
    "\n",
    "#sns.factorplot('Embarked', 'Survived', data=df, size=2, aspect=2)\n",
    "\n",
    "fig, (axis1, axis2, axis3) = plt.subplots(1,3,figsize=(15,2))\n",
    "sns.countplot(x='Embarked', data=df, ax=axis1)\n",
    "sns.countplot(x='Survived', hue='Embarked',data=df, order=[1,0],ax=axis2)\n",
    "\n",
    "# group by embarked, and get the mean for survived passengers for each value in Embarked\n",
    "embark_perc = df[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean()\n",
    "sns.barplot(x='Embarked', y='Survived',data=embark_perc, order=['S','C','Q'],ax=axis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- The most passengers embarked from 'S' station, followed by 'C' and 'Q'\n",
    "- The trend remains when we grouped them by Survived or not. \n",
    "- Survived people are mostly embarked from 'C'. \n",
    "My guess is that the Fare for \"C\" is also higher and they are mostly from first class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_perc = df[['Embarked','Fare']].groupby(['Embarked'],as_index=False).median()\n",
    "sns.barplot(x='Embarked', y='Fare',data=fare_perc, order=['S','C','Q'])\n",
    "\n",
    "sns.factorplot(\"Pclass\", col=\"Embarked\",  data=df,\n",
    "                   size=6, kind=\"count\", palette=\"muted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the most passengers from \"S\" and \"Q\" are in the 3rd class, whereas the most passengers from \"C\" are in the first class. The mean Fare price for \"C\" is also the highest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['Embarked', 'Survived','Pclass','Fare', 'Age', 'Sex']].groupby(['Embarked'], as_index=False).mean()\n",
    "df[['Embarked', 'Survived','Pclass','Fare', 'Age']].groupby(['Embarked'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survival rate changes with Embarked but it may actually due to other feasures, e.g., Pclass, Fare and Age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Remove 'S' dummy variable, and leave 'C' and 'Q', since they seem to have a good rate for survival. \n",
    "embark_dummies_df = pd.get_dummies(train_df['Embarked'])\n",
    "embark_dummies_df.drop('S', axis=1, inplace=True)\n",
    "\n",
    "df = df.join(embark_dummies_df)\n",
    "\n",
    "#df.drop(['Embarked'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip())\n",
    "# inspect the amount of people for each title\n",
    "df.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main titles are: \"Mr\",\"Miss\",\"Mrs\" & \"Master\". Some of the others can be merged into one of the four categories. The rest will be merged into \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].replace(['Mme','Lady','Ms','Mille','Miss'], 'Mrs')\n",
    "df.Title.loc[ (df.Title != 'Master') & (df.Title != 'Mr') & (df.Title != 'Mrs')] = 'Others'\n",
    "# inspect the correlation between Title and Survived\n",
    "#df[['Title','Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the amount of people for each title\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Title', data=df,ax=axis1)\n",
    "#sns.factorplot('Family', data=train_df, kind='count', ax=axis2)\n",
    "\n",
    "# average of survived for those who had/didn't have any families\n",
    "family_perc = df[['Title','Survived']].groupby(['Title'], as_index=False).mean()\n",
    "sns.barplot(x='Title',y='Survived',data=family_perc, ax=axis2)\n",
    "#axis1.set_xticklabels(['With Family','Alone'],rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Women and childen first\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use dummy variables for these titles and drop the orginal columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Title'])], axis=1).drop(labels=['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Title can be indicative of the Age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the amount of people for each title\n",
    "sns.factorplot(x='Title',y='Survived',hue='Sex', data=df, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x='Title',col='Survived',hue='Sex', data=df, kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the gender in \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any null values\n",
    "df['Pclass'].isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the corrleatoin between Pclass and survived\n",
    "#df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()\n",
    "g= sns.factorplot('Pclass','Survived', order=[1,2,3],data=train_df,size=3)\n",
    "g.set_ylabels('Survival Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a higher class has a higher survival rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the corrleatoin between Pclass and survived by Sex\n",
    "g= sns.factorplot('Pclass','Survived', hue ='Sex', order=[1,2,3],data=train_df, kind = 'bar', size=3)\n",
    "g.set_ylabels('Survival Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend remains when adding in the gender infromation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy variable for Pclass & drop the 3 rd class as it has the lowest average of survived passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pclass_dummies_df = pd.get_dummies(df['Pclass'])\n",
    "pclass_dummies_df.columns = ['Class1','Class2','Class3']\n",
    "#pclass_dummies_df.drop(['Class3'], axis=1, inplace=True)\n",
    "\n",
    "#df.drop(['Pclass'], axis=1, inplace=True)\n",
    "\n",
    "df = df.join(pclass_dummies_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "#train_df = train_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "#test_df = test_df.drop(['Name','Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill in NaN values of Age with the mean value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, children (age<16) on aboard eem to have a high chances for survival. so we can classify passengers as males, females, and child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map the two genders to 0 and 1\n",
    "df.Sex = df.Sex.map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspect the correlation between Sex and Survived \n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Sex', data=df, order=[1,0],ax=axis1)\n",
    "\n",
    "sex_perc = df[['Sex','Survived']].groupby(['Sex'], as_index=False).mean()\n",
    "sns.barplot(x='Sex',y='Survived',data=sex_perc, ax=axis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def get_person(passenger):\n",
    "    age, sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "\n",
    "df['Person'] = df[['Age','Sex']].apply(get_person, axis=1)\n",
    "\n",
    "df['Person'].head()\n",
    "\n",
    "# No need to use sex col since we created person col\n",
    "df.drop(['Sex'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# Create dummy variables for Person column, & drop male as it has the lowest average of surved passengers\n",
    "person_dummies_df = pd.get_dummies(df['Person'])\n",
    "#person_dummies_df.columns = ['Child','Female','Male']\n",
    "#person_dummies_df.drop(['Male'],axis=1, inplace=True)\n",
    "\n",
    "#df = df.join(person_dummies_df)\n",
    "\n",
    "# map the two genders to 0 and 1\n",
    "df.Sex = df.Sex.map({'male':0, 'female':1})\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Ticket.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Ticket.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are two types of tickects: (1)number only (2) letter+number. Tickets start with letters probably represent some special classes, and the first digit of the numbers may prepresent the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Ticket = df.Ticket.map(lambda x:x[0])\n",
    "df['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the amount of people for each type of tickets\n",
    "#df['Ticket'].value_counts()\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Ticket', data=df, ax=axis1)\n",
    "# inspect the correlatin between Ticket and Survived\n",
    "#df[['Ticket','Survived']].groupby(['Ticket'], as_index=False).mean()\n",
    "sex_perc = df[['Ticket','Survived']].groupby(['Ticket'], as_index=False).mean()\n",
    "sns.barplot(x='Ticket',y='Survived',data=sex_perc, ax=axis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the majority of the tickest are \"1\",\"2\",\"3\", and their survival rates are \"1\">\"2\">\"3\". The rates for others are low, except for \"9\"(2),\"C\"(77),\"F\"(13),\"P\"(98), and \"S\"(98). \"9\"\"F\" are very small samples. The high rates here are probably from Pclass or Fase. Let's check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['Ticket', 'Fare']].groupby(['Ticket'], as_index=False).mean()\n",
    "#df[['Ticket', 'Pclass']].groupby(['Ticket'], as_index=False).mean()\n",
    "\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "\n",
    "fare_perc = df[['Ticket','Fare']].groupby(['Ticket'], as_index=False).mean()\n",
    "sns.barplot(x='Ticket',y='Fare',data=fare_perc, ax=axis1)\n",
    "Pclass_perc = df[['Ticket','Pclass']].groupby(['Ticket'], as_index=False).mean()\n",
    "sns.barplot(x='Ticket',y='Pclass',data=Pclass_perc, ax=axis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Drop useless features & check the header.\n",
    "df.drop(labels=['PassengerId'], axis=1, iinplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop useless features and split the data into training and testing sets. Then i will use various models and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['PassengerId','Parch','SibSp','Title'], axis=1, inplace=True)\n",
    "\n",
    "X_train = df[0:891].drop(['Survived'], axis=1).values\n",
    "Y_train = df[0:891]['Survived'].values\n",
    "X_test  = df[891:].drop(['Survived'], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "#X_train = train_df.drop('Survived', axis=1)\n",
    "#Y_train = train_df['Survived']\n",
    "#X_test = test_df.drop('PassengerId', axis=1).copy()\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regress\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "#logreg.score(X_train, Y_train)\n",
    "logreg.score(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "svc.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ramdom Forests\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)\n",
    "Y_pred = rf.predict(X_test)\n",
    "print('Train accuracy with RF:', rf.score(X_train,Y_train))\n",
    "print('Train accuracy with RF:', rf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Specifying the parameter grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF has many parameters that we can tune. However, manually tuning them is very time-consuming. Thereby we use cross validation to search through these parameters to come up with best ones for our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "gaussian.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get Correlation Coefficient for each feasure using Logistic Regression\n",
    "coeff_df = DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df['Coefficient Estimate'] = pd.Series(logreg.coef_[0])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Gernerating Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({ \"PassengerId\": test_df[\"PassengerId\"], \"Survived\": Y_pred})\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
