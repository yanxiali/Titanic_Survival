{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# ignore Deprecation Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n",
    "Look at each attribute. Missing values will be filled. Catagorital feastures will be transformed to numberical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "df = train_df.append(test_df, ignore_index=True)\n",
    "# Some quick inspections\n",
    "print(train_df.shape, test_df.shape, train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df.info()\n",
    "#print('--------------------------')\n",
    "#test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only \"Age\", \"Cabin\", \"Embarked\", \"Fare\", and \"Survived\" has null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 263 missing values in Age. This can be inferred from other feasures, e.g., Title, Fare, SibSp, Parch, etc. will come back to this after finishing inspecting other features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get average, std, and number of NaN values in train_df\n",
    "averge_age_df = df['Age'].mean()\n",
    "std_age_df = df['Age'].std()\n",
    "count_nan_age_df = df['Age'].isnull().sum()\n",
    "\n",
    "# generate random numbers between (mean-std) & (mean+std)\n",
    "rand_1 = np.random.randint(averge_age_df - std_age_df, averge_age_df + std_age_df, size=count_nan_age_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1, axis2) = plt.subplots(1,2,figsize=(15,4))\n",
    "axis1.set_title('Original Age values - Titanic')\n",
    "axis2.set_title('New Age values - Titanic')\n",
    "# plot original Age values\n",
    "# NOTE: drop all null values, and convert to int\n",
    "df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
    "\n",
    "# fill NaN values in Age column with random values generated\n",
    "df['Age'][np.isnan(df['Age'])] = rand_1\n",
    "\n",
    "# convert from float to int\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "# plot new Age values\n",
    "df['Age'].hist(bins=70, ax=axis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks for survived/not survived passengers by their age\n",
    "facet = sns.FacetGrid(df, hue = 'Survived', aspect=4)\n",
    "facet.map(sns.distplot, 'Age')\n",
    "#facet.map(sns.kdeplot, 'Age', shade=True)\n",
    "facet.set(xlim=(0, df['Age'].max()))\n",
    "facet.add_legend()\n",
    "\n",
    "# Averge survived passeangers by age\n",
    "fig, axis1 = plt.subplots(1, 1, figsize=(18,4))\n",
    "average_age = df[['Age','Survived']].groupby(['Age'], as_index=False).mean()\n",
    "sns.barplot(x='Age', y='Survived', data=average_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NAN\n",
    "df.Cabin.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is highly imcomplete. There are two choices: (1)map the missing ones to a new category \"unknown\" (2) drop this feasure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NAN\n",
    "df.Embarked.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna({'Embarked':'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "sns.factorplot('Embarked', 'Survived', data=df, size=2, aspect=2)\n",
    "\n",
    "fig, (axis1, axis2, axis3) = plt.subplots(1,3,figsize=(15,2))\n",
    "sns.countplot(x='Embarked', data=df, ax=axis1)\n",
    "sns.countplot(x='Survived', hue='Embarked',data=df, order=[1,0],ax=axis2)\n",
    "\n",
    "# group by embarked, and get the mean for survived passengers for each value in Embarked\n",
    "embark_perc = df[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean()\n",
    "sns.barplot(x='Embarked', y='Survived',data=embark_perc, order=['S','C','Q'],ax=axis3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the correlation between Embarked and Survived as well as some other features\n",
    "#df[['Embarked', 'Survived','Pclass','Fare', 'Age', 'Sex']].groupby(['Embarked'], as_index=False).mean()\n",
    "df[['Embarked', 'Survived','Pclass','Fare', 'Age']].groupby(['Embarked'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survival rate changes with Embarked but it may actually due to other feasures, e.g., Pclass, Fare and Age. Thereby, this feature can be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Remove 'S' dummy variable, and leave 'C' and 'Q', since they seem to have a good rate for survival. \n",
    "#embark_dummies_titanic = pd.get_dummies(train_df['Embarked'])\n",
    "#embark_dummies_titanic.drop('S', axis=1, inplace=True)\n",
    "\n",
    "#embark_dummies_test = pd.get_dummies(train_df['Embarked'])\n",
    "#embark_dummies_test.drop('S', axis=1, inplace=True)\n",
    "\n",
    "#train_df = train_df.join(embark_dummies_titanic)\n",
    "#test_df = test_df.join(embark_dummies_test)\n",
    "\n",
    "#train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "#test_df.drop(['Embarked'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NAN\n",
    "df.Fare.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one missing Fare value. It can probably be inferred from Ticket, Pclass, Cabin, etc. Let's see the corresponding values of for these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Ticket[df.Fare.isnull()],df.Pclass[df.Fare.isnull()],df.Embarked[df.Fare.isnull()],df.Cabin[df.Fare.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no corresponding value for Cabin, so only look at the relation between Fare and the other three feasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axis1, axis2, axis3) = plt.subplots(1,3, sharex=False, figsize=(10,2))\n",
    "\n",
    "Ticket_perc = df[['Ticket','Fare']].groupby(['Ticket'], as_index=False).mean()\n",
    "sns.barplot(x='Ticket',y='Fare',data=Ticket_perc, ax=axis1)\n",
    "\n",
    "Pclass_perc = df[['Pclass','Fare']].groupby(['Pclass'], as_index=False).mean()\n",
    "sns.barplot(x='Pclass',y='Fare',data=Pclass_perc, ax=axis2)\n",
    "\n",
    "Embarked_perc = df[['Embarked','Fare']].groupby(['Embarked'], as_index=False).mean()\n",
    "sns.barplot(x='Embarked',y='Fare',data=Embarked_perc, ax=axis3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use boxplot to visualize the distribution of Fare for each Pclass\n",
    "fig, (axis1, axis2, axis3) = plt.subplots(3,1, sharex=False, figsize=(10,8))\n",
    "sns.boxplot('Ticket','Fare',data=df, ax=axis1)\n",
    "axis1.set_ylim([0,300])\n",
    "sns.boxplot('Pclass','Fare',data=df, ax=axis2)\n",
    "axis2.set_ylim(0,300)\n",
    "sns.boxplot('Embarked','Fare',data=df, ax=axis3)\n",
    "axis3.set_ylim(0,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Fare does correlate with Ticket, Pclass & Embarked. Thereby I will guess the missing value using the median value of (Pcalss = 3) & (Ticket = 3) & (Embarked = S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fare_guess = df.Fare.loc[ (df.Ticket == '3') & (df.Pclass == 3) & (df.Embarked == 'S') ].median()\n",
    "df.Fare.fillna(Fare_guess, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will inspect the mean Fare values for people died and survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(df, hue=\"Survived\",aspect=1.5,size=2)\n",
    "facet.map(plt.hist,'Fare', bins=range(0,210,10),alpha=0.5)\n",
    "facet.add_legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fare for survived & didn't survived passengers\n",
    "fare_not_survived = df['Fare'][df['Survived'] == 0]\n",
    "fare_survived = df['Fare'][df['Survived'] == 1]\n",
    "\n",
    "# Get average and std for fare of survived/not survived passengers\n",
    "average_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
    "std_fare = DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
    "\n",
    "# plot\n",
    "df['Fare'].plot(kind='hist', figsize=[15,3],bins=100,xlim=(0,50))\n",
    "average_fare.index.names = std_fare.index.names = ['Survived']\n",
    "average_fare.plot(yerr=std_fare, kind='bar', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the correlation between Fare and Survived using a scatter plot\n",
    "df[['Fare','Survived']].groupby(['Fare'],as_index=False).mean().plot.scatter('Fare','Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin Fare into five intervals with equal amount of people\n",
    "df['Fare_bin'] = pd.qcut(df.Fare,5,labels=[1,2,3,4,5]).astype(int)\n",
    "\n",
    "# inspect the correlation between Fare-bin and Survived\n",
    "df[['Fare_bin', 'Survived']].groupby(['Fare_bin'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Fare_bin','Survived']].groupby(['Fare_bin'],as_index=False).mean().plot.scatter('Fare_bin','Survived')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the correlation between Fare and Survived is clear after the binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip())\n",
    "# inspect the amount of people for each title\n",
    "df.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main titles are: \"Mr\",\"Miss\",\"Mrs\" & \"Master\". Some of the others can be merged into one of the four categories. The rest will be merged into \"Others\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].replace('Mlle','Miss')\n",
    "df['Title'] = df['Title'].replace(['Mme','Lady','Ms'], 'Mrs')\n",
    "df.Title.loc[ (df.Title != 'Master') & (df.Title != 'Mr') & (df.Title != 'Miss') & (df.Title != 'Mrs')] = 'Others'\n",
    "# inspect the correlation between Title and Survived\n",
    "#df[['Title','Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the amount of people for each title\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Title', data=df,ax=axis1)\n",
    "#sns.factorplot('Family', data=train_df, kind='count', ax=axis2)\n",
    "\n",
    "# average of survived for those who had/didn't have any families\n",
    "family_perc = df[['Title','Survived']].groupby(['Title'], as_index=False).mean()\n",
    "sns.barplot(x='Title',y='Survived',data=family_perc, ax=axis2)\n",
    "#axis1.set_xticklabels(['With Family','Alone'],rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use dummy variables for these titles and drop the orginal columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Title'])], axis=1).drop(labels=['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parch & SibSp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having 2 columns, Parch and SibSp, we can have only one column representing if the passenger had any families aboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Family'] = df['Parch']+df['SibSp']+1\n",
    "# inspect the correlation between Family and Survived\n",
    "df[['Family', 'Survived']].groupby(['Family'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the number of family members\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Family', data=df, ax=axis1)\n",
    "\n",
    "# average of survived for those who had/didn't have any families\n",
    "family_perc = df[['Family','Survived']].groupby(['Family'], as_index=False).mean()\n",
    "sns.barplot(x='Family',y='Survived',data=family_perc, ax=axis2)\n",
    "#axis1.set_xticklabels(['With Family','Alone'],rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the family size\n",
    "df['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survivial rate increases with the family size till Family>=5. However, the number of family with >=5 members is only 57. Besides, peole with big families (>=5) have a low survival rate too. Thereby, I will combine the data with Family>4 into one category, Family=5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Family = df.Family.map(lambda x: 5 if x>4 else x)\n",
    "df[['Family','Survived']].groupby(['Family'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of family members\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Family', data=df, ax=axis1)\n",
    "\n",
    "# average of survived for those who had/didn't have any families\n",
    "family_perc = df[['Family','Survived']].groupby(['Family'], as_index=False).mean()\n",
    "sns.barplot(x='Family',y='Survived',data=family_perc, ax=axis2)\n",
    "#axis1.set_xticklabels(['With Family','Alone'],rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"Parch\" & \"SibSp\"\n",
    "#df = df.drop(['Parch','SibSp'], axis=1)\n",
    "#df = df.drop(['Parch','SibSp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any null values\n",
    "df['Pclass'].isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the corrleatoin between Pclass and survived\n",
    "#df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()\n",
    "sns.factorplot('Pclass','Survived', order=[1,2,3],data=train_df,size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a higher class has a higher survival rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy variable for Pclass & drop the 3 rd class as it has the lowest average of survived passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_dummies_df = pd.get_dummies(df['Pclass'])\n",
    "pclass_dummies_df.columns = ['Class1','Class2','Class3']\n",
    "#pclass_dummies_df.drop(['Class3'], axis=1, inplace=True)\n",
    "\n",
    "#df.drop(['Pclass'], axis=1, inplace=True)\n",
    "\n",
    "df = df.join(pclass_dummies_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "#train_df = train_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "#test_df = test_df.drop(['Name','Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill in NaN values of Age with the mean value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, children (age<16) on aboard eem to have a high chances for survival. so we can classify passengers as males, females, and child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sex.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map the two genders to 0 and 1\n",
    "df.Sex = df.Sex.map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the correlation between Sex and Survived \n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Sex', data=df, order=[1,0],ax=axis1)\n",
    "\n",
    "sex_perc = df[['Sex','Survived']].groupby(['Sex'], as_index=False).mean()\n",
    "sns.barplot(x='Sex',y='Survived',data=sex_perc, ax=axis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_person(passenger):\n",
    "    age, sex = passenger\n",
    "    return 'child' if age < 16 else sex\n",
    "\n",
    "df['Person'] = df[['Age','Sex']].apply(get_person, axis=1)\n",
    "\n",
    "df['Person'].head()\n",
    "\n",
    "# No need to use sex col since we created person col\n",
    "df.drop(['Sex'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "# Create dummy variables for Person column, & drop male as it has the lowest average of surved passengers\n",
    "person_dummies_df = pd.get_dummies(df['Person'])\n",
    "#person_dummies_df.columns = ['Child','Female','Male']\n",
    "#person_dummies_df.drop(['Male'],axis=1, inplace=True)\n",
    "\n",
    "#df = df.join(person_dummies_df)\n",
    "\n",
    "# map the two genders to 0 and 1\n",
    "df.Sex = df.Sex.map({'male':0, 'female':1})\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Ticket.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Ticket.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are two types of tickects: (1)number only (2) letter+number. Tickets start with letters probably represent some special classes, and the first digit of the numbers may prepresent the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Ticket = df.Ticket.map(lambda x:x[0])\n",
    "df['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the amount of people for each type of tickets\n",
    "#df['Ticket'].value_counts()\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "sns.countplot(x='Ticket', data=df, ax=axis1)\n",
    "# inspect the correlatin between Ticket and Survived\n",
    "#df[['Ticket','Survived']].groupby(['Ticket'], as_index=False).mean()\n",
    "sex_perc = df[['Ticket','Survived']].groupby(['Ticket'], as_index=False).mean()\n",
    "sns.barplot(x='Ticket',y='Survived',data=sex_perc, ax=axis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the majority of the tickest are \"1\",\"2\",\"3\", and their survival rates are \"1\">\"2\">\"3\". The rates for others are low, except for \"9\"(2),\"C\"(77),\"F\"(13),\"P\"(98), and \"S\"(98). \"9\"\"F\" are very small samples. The high rates here are probably from Pclass or Fase. Let's check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['Ticket', 'Fare']].groupby(['Ticket'], as_index=False).mean()\n",
    "#df[['Ticket', 'Pclass']].groupby(['Ticket'], as_index=False).mean()\n",
    "\n",
    "fig, (axis1, axis2) = plt.subplots(1,2, sharex=True, figsize=(10,2))\n",
    "\n",
    "fare_perc = df[['Ticket','Fare']].groupby(['Ticket'], as_index=False).mean()\n",
    "sns.barplot(x='Ticket',y='Fare',data=fare_perc, ax=axis1)\n",
    "Pclass_perc = df[['Ticket','Pclass']].groupby(['Ticket'], as_index=False).mean()\n",
    "sns.barplot(x='Ticket',y='Pclass',data=Pclass_perc, ax=axis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop useless features and split the data into training and testing sets. Then i will use various models and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PassengerId','Parch','SibSp','Title'], axis=1, inplace=True)\n",
    "\n",
    "X_train = df[0:891].drop(['Survived'], axis=1).values\n",
    "Y_train = df[0:891]['Survived'].values\n",
    "X_test  = df[891:].drop(['Survived'], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "#X_train = train_df.drop('Survived', axis=1)\n",
    "#Y_train = train_df['Survived']\n",
    "#X_test = test_df.drop('PassengerId', axis=1).copy()\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regress\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "#logreg.score(X_train, Y_train)\n",
    "logreg.score(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)\n",
    "Y_pred = svc.predict(X_test)\n",
    "svc.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramdom Forests\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)\n",
    "Y_pred = rf.predict(X_test)\n",
    "rf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "gaussian.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Correlation Coefficient for each feasure using Logistic Regression\n",
    "coeff_df = DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df['Coefficient Estimate'] = pd.Series(logreg.coef_[0])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({ \"PassengerId\": test_df[\"PassengerId\"], \"Survived\": Y_pred})\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
